{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les Biblioteques dont on aura besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des biliotheques\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# traitement de texte\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import pickle\n",
    "# manipuler les donnees\n",
    "import numpy as np\n",
    "import random\n",
    "# deep learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "\n",
    "# creer un objet WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# importer la base des connaissances\n",
    "words=[]\n",
    "tags = []\n",
    "words_tags = []\n",
    "ignore_words = ['?', '!','.',',']\n",
    "data_file = open(\"rabat.json\").read()\n",
    "data = json.loads(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-traitement des données\n",
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenisation des pattern (les découper en des mots)\n",
    "        tokens = nltk.word_tokenize(pattern)\n",
    "        words.extend(tokens)\n",
    "        #on joint les tokens (mots cles) avec leur tag et on les ajoute a words_tags\n",
    "        words_tags.append((tokens, intent['tag']))\n",
    "        # on ajoute les tags a une liste de tag\n",
    "        if intent['tag'] not in tags:\n",
    "            tags.append(intent['tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on fait la lemmatisation des mots cles, et on supprime les dupliqués\n",
    "\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# trier et supprimer les tags dupliqués s'il y en a\n",
    "tags = sorted(list(set(tags)))\n",
    "\n",
    "# creating a pickle file to store the Python objects which we will use while predicting\n",
    "# creation de deux fichier pickle pour enregistrer les resultats du prétraitement des données\n",
    "pickle.dump(words,open('words.pkl','wb')) \n",
    "pickle.dump(tags,open('tags.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation des données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data created\n"
     ]
    }
   ],
   "source": [
    "# creation des données d'entrainement\n",
    "training = []\n",
    "\n",
    "# creation d'un tableau vide pour le resultat (output)\n",
    "output_empty = [0] * len(tags)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for word_tag in words_tags:\n",
    "    # initialisation d'un sac de mots\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = word_tag[0]\n",
    "   \n",
    "    # lemmatiser les mots\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    \n",
    "    # si on trouve un mot qui se trouve dans le pattern actuel, on ajoute à sa position (son index) 1\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    # la sortie est '0' pour les autres tags et '1' pour le tag actuel (et ce pour chaque pattern)\n",
    "    output = list(output_empty)\n",
    "    output[tags.index(word_tag[1])] = 1\n",
    "    training.append([bag, output])\n",
    "\n",
    "# shuffle features and converting it into numpy arrays\n",
    "# mélanger les donnees et les convertir en un tableau de numpy\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# creation des tableaux d'entrainement et de teste\n",
    "input_x = list(training[:,0])\n",
    "output_y = list(training[:,1])\n",
    "\n",
    "print(\"Training data created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 4ms/step - loss: 2.2841 - accuracy: 0.1321\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8807 - accuracy: 0.3019\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5487 - accuracy: 0.3774\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1637 - accuracy: 0.6698\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8035 - accuracy: 0.8491\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.9057\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9811\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0895 - accuracy: 0.9906\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9906\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9717\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 0.9906\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9906\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9906\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create NN model to predict the responses\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(len(input_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(output_y[0]), activation='softmax'))\n",
    "\n",
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "#fitting and saving the model \n",
    "hist = model.fit(np.array(input_x), np.array(output_y), epochs=20, batch_size=64, verbose=1)\n",
    "model.save('chatbot.h5', hist) # we will pickle this model to use in the future\n",
    "print(\"\\n\")\n",
    "print(\"*\"*50)\n",
    "print(\"\\nModel Created Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the further steps, we will import all the libraries and Train_Bot json data and use the pickled model for the prediction of responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating all the above steps and using the pickled model for the prediction of responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model file\n",
    "model = load_model('chatbot.h5')\n",
    "# intents = json.loads(open(\"Train_Bot.json\").read())\n",
    "intents = json.loads(open(\"rabat.json\").read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "tags = pickle.load(open('tags.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "\n",
    "    # tokenize the pattern - split words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # stem each word - create short form for word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "\n",
    "def bow(sentence, words, show_details=True):\n",
    "\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "               \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "   \n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    error = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>error]\n",
    "    \n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    \n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the response from the model\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "# function to predict the class and get the response\n",
    "\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to start the chat bot which will continue till the user type 'end'\n",
    "\n",
    "def start_chat():\n",
    "    print(\"Bot: This is Tourism! Your Virtual Assistant.\\n\\n\")\n",
    "    while True:\n",
    "        inp = str(input()).lower()\n",
    "        if inp.lower()==\"end\":\n",
    "            break\n",
    "        if inp.lower()== '' or inp.lower()== '*':\n",
    "            print('Please re-phrase your query!')\n",
    "            print(\"-\"*50)\n",
    "        else:\n",
    "            print(f\"Bot: {chatbot_response(inp)}\"+'\\n')\n",
    "            print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatting with BOT using the Command Line Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the chat bot\n",
    "# start_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatting with BOT using the Tkinter App\n",
    "\n",
    "#### **For running the Tkinter GUI you have to download this notebook in ipynb format and run using jupyter notebook in your local machine/pc because in google colab, you cannot run Tkinter apps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hicha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\2650693826.py\", line 52, in send_msz\n",
      "    lab = f\"Bot: {chatbot_response(usr_input)}\"+'\\n'\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\1473686815.py\", line 15, in chatbot_response\n",
      "    ints = predict_class(text, model)\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\495361269.py\", line 43, in predict_class\n",
      "    return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
      "NameError: name 'classes' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hicha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\2650693826.py\", line 52, in send_msz\n",
      "    lab = f\"Bot: {chatbot_response(usr_input)}\"+'\\n'\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\1473686815.py\", line 15, in chatbot_response\n",
      "    ints = predict_class(text, model)\n",
      "  File \"C:\\Users\\hicha\\AppData\\Local\\Temp\\ipykernel_13984\\495361269.py\", line 43, in predict_class\n",
      "    return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
      "NameError: name 'classes' is not defined\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "\n",
    "root=tk.Tk()\n",
    "filename=\"Chat Bot\"\n",
    "root.title(f\"Chat Bot\")\n",
    "root.geometry('500x400')\n",
    "root.resizable(False, False)\n",
    "message=tk.StringVar()\n",
    "\n",
    "chat_win=Frame(root,bd=1,bg='white',width=50,height=8)\n",
    "chat_win.place(x=6,y=6,height=300,width=488)\n",
    "\n",
    "textcon=tk.Text(chat_win,bd=1,bg='white',width=50,height=8)\n",
    "textcon.pack(fill=\"both\",expand=True)\n",
    "\n",
    "mes_win=Entry(root,width=30,xscrollcommand=True,textvariable=message)\n",
    "mes_win.place(x=6,y=310,height=60,width=380)\n",
    "mes_win.focus()\n",
    "\n",
    "textcon.config(fg='black')\n",
    "textcon.tag_config('usr',foreground='black')\n",
    "textcon.insert(END,\"Bot: This is Ibn Battuta! Your Personal Assistant.\\n\\tIf you want to know where to stay, where to visit\\nor even where to eat your lunch here in Rabat don't hesitate to ask\\n\")\n",
    "mssg=mes_win.get()\n",
    "\n",
    "exit_list = ['exit','break','quit','see you later','chat with you later','end the chat','bye','ok bye']\n",
    "\n",
    "def greet_res(text):\n",
    "    text=text.lower()\n",
    "    bot_greet=['hi','hello','hola','hey','howdy']\n",
    "    usr_greet=['hi','hey','hello','hola','greetings','wassup','whats up']\n",
    "    for word in text.split():\n",
    "        if word in usr_greet:\n",
    "            return random.choice(bot_greet)\n",
    "\n",
    "def send_msz(event=None):\n",
    "    usr_input = message.get()\n",
    "    usr_input = usr_input.lower()\n",
    "    textcon.insert(END, f'You: {usr_input}'+'\\n','usr')\n",
    "    if usr_input in exit_list:\n",
    "        textcon.config(fg='black')\n",
    "        textcon.insert(END,\"Bot: Ok bye! Chat with you later\\n\")\n",
    "        return root.destroy()\n",
    "    else:\n",
    "        textcon.config(fg='black')\n",
    "        if greet_res(usr_input) != None:\n",
    "            lab=f\"Bot: {greet_res(usr_input)}\"+'\\n'\n",
    "            textcon.insert(END,lab)\n",
    "            mes_win.delete(0,END)\n",
    "        else:\n",
    "            lab = f\"Bot: {chatbot_response(usr_input)}\"+'\\n'\n",
    "            textcon.insert(END,lab)\n",
    "            mes_win.delete(0,END)\n",
    "\n",
    "button_send=Button(root,text='Send',bg='dark green',activebackground='grey',command=send_msz,width=12,height=5,font=('Arial'))\n",
    "button_send.place(x=376,y=310,height=60,width=110)\n",
    "root.bind('<Return>', send_msz,button_send)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27c5c81ded9e3cb6d5e2e7b5bcca8d6bd67c415cbc402cbae9698c8216c19643"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
